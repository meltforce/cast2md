# cast2md - Project Knowledge

## Deployment

The production server runs on `cast2md` (Tailscale hostname).

**Important:** Always commit, push, and deploy before testing any server-relevant code changes. The server runs from the git repository, not from your local files.

To deploy:
```bash
git add -A && git commit -m "Your message" && git push
ssh root@cast2md "cd /opt/cast2md && git pull && systemctl restart cast2md"
```

## Architecture

- **Server**: Runs on cast2md via systemd (`systemctl restart cast2md`)
- **Node workers**: Remote transcription nodes connect to the server
- **Local workers**: Download workers and one local transcription worker run on the server

## Development

- Status UI: https://cast2md.leo-royal.ts.net/status
- API docs: https://cast2md.leo-royal.ts.net/docs

## Documentation

- `cast2md-requirements.md` - Central requirements document with architecture, data model, and development phases
- `docs/` - Additional documentation (distributed transcription setup, architecture diagrams, etc.)

## Testing

Always test the server API directly via the URL, not by SSH + localhost:
```bash
# Good - direct API call
curl https://cast2md.leo-royal.ts.net/api/health

# Bad - unnecessary SSH
ssh root@cast2md "curl localhost:8000/api/health"
```

## Re-transcription

Episodes track which Whisper model was used for transcription (`transcript_model` column). When the configured model changes, episodes can be re-transcribed:

- **Episode detail page**: Shows model name next to transcript, offers re-transcribe button if model differs
- **Feed detail page**: Shows count of outdated episodes with batch re-transcribe button
- **API endpoints**:
  - `GET /api/queue/retranscribe/info/{feed_id}` - get current model and count
  - `POST /api/queue/episodes/{id}/retranscribe` - queue single episode
  - `POST /api/queue/batch/feed/{id}/retranscribe` - queue all outdated in feed

Existing episodes before this feature have `transcript_model = NULL` and will show as needing re-transcription.

## iTunes URL Support

Feeds can be added via Apple Podcasts URLs. The system automatically resolves them to RSS feed URLs.

### How It Works

1. `feed/itunes.py:resolve_feed_url()` detects Apple Podcasts URLs
2. Extracts iTunes ID from URL pattern `podcasts.apple.com/.*/id(\d+)`
3. Calls iTunes Lookup API to get RSS feed URL
4. Stores `itunes_id` on the feed for reference

### Key Files

- `clients/itunes.py` - iTunes API client (`ItunesClient.lookup()`)
- `feed/itunes.py` - URL detection and resolution
- `api/feeds.py:create_feed()` - Calls `resolve_feed_url()` before validation

## Transcript Sources

Episodes track where their transcript came from via `transcript_source` column:

- `whisper` - Self-transcribed using Whisper
- `podcast2.0:vtt` - Downloaded from publisher (WebVTT format)
- `podcast2.0:srt` - Downloaded from publisher (SRT format)
- `podcast2.0:json` - Downloaded from publisher (JSON format)
- `podcast2.0:text` - Downloaded from publisher (plain text)
- `pocketcasts` - Auto-generated by Pocket Casts
- `NULL` - Legacy episodes (before this feature)

### Transcript-First Workflow

When a feed is added or refreshed, the system queues `TRANSCRIPT_DOWNLOAD` jobs:

1. `feed/discovery.py:discover_new_episodes()` queues `TRANSCRIPT_DOWNLOAD` jobs (not `DOWNLOAD`)
2. `worker/manager.py:_process_transcript_download_job()` tries external providers
3. If transcript found: saves it, marks episode `COMPLETED` (no audio needed)
4. If not found: episode stays `PENDING` for manual audio download

This is storage-efficient - audio is only downloaded when transcripts aren't available externally.

### Provider Priority

1. **Podcast20Provider** - RSS `<podcast:transcript>` tags (authoritative)
2. **PocketCastsProvider** - Auto-generated transcripts (fallback)
3. **Whisper** - Self-transcription (only after audio download)

### Pocket Casts Provider

Uses public Pocket Casts API (no authentication required):

1. Search API: `POST podcast-api.pocketcasts.com/discover/search`
2. Show notes API: `GET podcast-api.pocketcasts.com/mobile/show_notes/full/{uuid}`
   - Returns redirect to static JSON, must follow redirects
3. Downloads from `pocket_casts_transcripts[]` array (VTT format)

The provider:
- Searches by feed title, matches by author
- Caches `pocketcasts_uuid` on feed after first successful search
- Matches episodes by title similarity + published date within 24h

### Adding New Providers

1. Create `src/cast2md/transcription/providers/newprovider.py`
2. Implement `TranscriptProvider` base class:
   - `source_id` property (e.g., `"newprovider"`)
   - `can_provide(episode, feed)` - check if provider applies
   - `fetch(episode, feed)` - download and return `TranscriptResult`
3. Register in `providers/__init__.py`:
   ```python
   _providers = [
       Podcast20Provider(),
       PocketCastsProvider(),
       NewProvider(),  # Add here
   ]
   ```

### Key Files

- `clients/pocketcasts.py` - Pocket Casts API client
- `transcription/providers/base.py` - `TranscriptProvider` abstract base class
- `transcription/providers/podcast20.py` - Podcasting 2.0 implementation
- `transcription/providers/pocketcasts.py` - Pocket Casts implementation
- `transcription/providers/__init__.py` - Provider registry and `try_fetch_transcript()`
- `transcription/formats.py` - VTT/SRT/JSON/text parsers
- `worker/manager.py:_process_transcript_download_job()` - Transcript download handler
- `worker/manager.py:_queue_transcription()` - Post-download transcription (Whisper fallback)

## Web UI Workflow

### Feed Episode List (feed_detail.html)

The episode list uses a **transcript-first** approach with real-time status updates:

#### Button Behavior

| Episode Status | Button | Action |
|----------------|--------|--------|
| `pending` | "Get Transcript" | Queues `TRANSCRIPT_DOWNLOAD` job |
| `downloaded` | "Transcribe" | Queues `TRANSCRIBE` job (Whisper) |
| `failed` | "Retry" | Queues `DOWNLOAD` job |
| `downloading`, `transcribing`, `queued` | "..." (disabled) | No action, status shown in badge |
| `completed` | (none) | Link to episode detail |

#### Transcript Download Flow

1. User clicks "Get Transcript" → `POST /api/queue/episodes/{id}/transcript-download`
2. Button becomes disabled ("..."), status badge shows "queued"
3. Worker tries Podcast20Provider, then PocketCastsProvider
4. If found: episode marked `COMPLETED`, button becomes link to detail
5. If not found: episode returns to `PENDING`, button shows "Download Audio"

When transcript download fails (no external transcript available), the button changes to "Download Audio" which queues the full audio download + Whisper transcription pipeline.

#### Real-time Status Updates

The feed page polls `/api/feeds/{id}/episodes` every 2 seconds while jobs are in progress:

- `startStatusPolling()` - Starts interval timer
- `stopStatusPolling()` - Stops when all visible episodes are completed/failed/pending
- `pollEpisodeStatus()` - Fetches current status and updates DOM
- `updateEpisodeRow()` - Updates badge, checkbox, and action button

Polling uses visible episode IDs from DOM (not template-rendered array) to handle pagination correctly.

#### Batch Operations

- "Get All Transcripts" button queues all pending episodes via `POST /api/queue/batch/feed/{id}/transcript-download`
- "Re-transcribe Outdated" button queues Whisper jobs for episodes with old model

### Episode Detail Page (episode_detail.html)

Shows full episode info with transcript viewer and manual action buttons:

| Status | Available Actions |
|--------|-------------------|
| `pending` | "Try Transcript Download", "Download Audio" |
| `downloaded` | "Queue Transcription" |
| `completed` | "Delete Audio" (if audio exists), "Download Audio" (if deleted) |
| `failed` | "Retry" |

### Queue API Endpoints

| Endpoint | Description |
|----------|-------------|
| `POST /api/queue/episodes/{id}/process` | Download audio (creates `DOWNLOAD` job) |
| `POST /api/queue/episodes/{id}/transcribe` | Whisper transcription (creates `TRANSCRIBE` job) |
| `POST /api/queue/episodes/{id}/transcript-download` | Try external providers (creates `TRANSCRIPT_DOWNLOAD` job) |
| `POST /api/queue/episodes/{id}/retranscribe` | Re-transcribe with current model |
| `POST /api/queue/batch/feed/{id}/transcript-download` | Batch transcript download for all pending |
| `POST /api/queue/batch/feed/{id}/retranscribe` | Batch re-transcribe for outdated episodes |

## Audio Management

Episodes with external transcripts don't need audio files. The audio can be deleted to save space:

- `DELETE /api/episodes/{id}/audio` - Deletes audio file, keeps `audio_url` for re-download
- Only allowed if episode has a transcript
- Episode detail page shows "Delete Audio" / "Download Audio" buttons accordingly

## Feed Deletion and Trash

When a feed is deleted, files are moved to trash instead of being permanently deleted:

### How It Works

1. User clicks "Delete Feed" on feed detail page
2. Confirmation dialog requires typing "delete"
3. `DELETE /api/feeds/{id}` moves files to trash, then deletes DB records
4. Server auto-cleans trash entries older than 30 days on startup

### Trash Structure

```
{storage_path}/trash/{feed_slug}_{feed_id}_{timestamp}/
├── audio/
│   └── {feed_id}/
│       └── *.mp3
└── transcripts/
    └── {feed_id}/
        └── *.json
```

### Key Files

- `storage/filesystem.py` - `move_feed_to_trash()`, `cleanup_old_trash()`
- `api/feeds.py:delete_feed()` - Calls trash functions before DB deletion
- `main.py:lifespan()` - Runs cleanup on server startup

### Limitations

- DB records are deleted immediately (no restore from trash)
- Only files are preserved in trash
- Manual restore requires re-adding feed and copying files back
